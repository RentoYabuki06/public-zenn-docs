---
title: "【簡単】初期の将棋AIを自作してみよう（ミニマックス）"
emoji: "🌊"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["AI","Python","minimax法", "将棋AI"]
published: false
---

将棋AIを自作するプロジェクトは、コンピュータ科学、特に機械学習と人工知能の理解を深める絶好の機会です。この記事では、基本的な将棋AIを作成するためのステップをガイドとして提供します。使用する言語はPythonですが、他のプログラミング言語にも応用可能です。

# 0. ミニマックス法について

将棋AIの実装において重要な探索アルゴリズムであるミニマックス法について、その歴史や問題点も含めて解説します。

## ミニマックス法の歴史

ミニマックス法は、ゲーム理論の一部として1930年代にジョン・フォン・ノイマンによって体系化されました。この理論は、二人対戦ゲームにおける最適戦略を見つけるために用いられ、特にチェスのような完全情報ゲームにおいて効果を発揮します。将棋もこれに類似しており、プレイヤーは常に全ての情報を持っており、相手の手もすべて予測可能です。

## ミニマックス法の概念

ミニマックス法は、最悪の場合でも最良の結果を保証する戦略を採用します。具体的には、プレイヤーは自分にとって最良の結果をもたらす手を選び、同時に相手がその次に取りうる最良の手（自分にとっての最悪の結果）を考慮に入れます。このプロセスをゲームの終了まで繰り返し、最適な戦略を導き出します。

## ミニマックス法の問題点

1. **計算量が大きい**: ミニマックス法は全ての可能な手のシーケンスを評価する必要があるため、ゲームの複雑さが増すと非常に大きな計算量を要します。これは、特に将棋のような多くの可能な手があるゲームで問題となります。

2. **効率的な評価関数が必要**: 各盤面の評価が不正確だと、最適な戦略が導き出されません。正確な評価関数を設計することは、特に多様な状況が存在するゲームでは困難です。

3. **アルファベータ枝刈りの必要性**: アルファベータ枝刈りはミニマックス法の計算量を減少させる手法で、無駄な探索を避けるために「枝を刈る」ことで探索空間を削減します。しかし、この方法を適用してもなお、探索する必要があるケースが多く残ります。

## ミニマックス法の改善策



ミニマックス法は、その計算

# 1. 環境設定

まず、Pythonと必要なライブラリをインストールします。AI開発に役立つ主要なライブラリには、`numpy`（数学的計算を助ける）、`pandas`（データの整理）、`tensorflow`や`pytorch`（機械学習ライブラリ）があります。

```bash
pip install numpy pandas tensorflow pytorch
```

# 2. 将棋のルール実装

将棋のルールをコードで表現する必要があります。これには、盤面の状態を表すクラスと、可能な手を生成するメソッドが必要です。

```python
class ShogiBoard:
    def __init__(self):
        self.board = self.initialize_board()

    def initialize_board(self):
        # 初期盤面の設定
        return board

    def generate_legal_moves(self):
        # 合法手の生成
        return moves
```

# 3. 評価関数の作成

AIがどの手を選ぶかを決定するためには、各盤面を評価する関数が必要です。この関数は、盤面を数値で評価し、AIが最も有利と判断する手を選びます。

```python
def evaluate_board(board):
    # 盤面の評価
    score = 0
    # 盤面の各駒の位置を評価してscoreに加算
    return score
```

# 4. 探索アルゴリズムの実装

一般的な探索アルゴリズムにはミニマックス法があります。これを使って、AIが最適な手を選ぶようにします。

```python
def minimax(board, depth, maximizingPlayer):
    if depth == 0 or game_over(board):
        return evaluate_board(board)

    if maximizingPlayer:
        maxEval = float('-inf')
        for move in board.generate_legal_moves():
            evaluation = minimax(move, depth-1, False)
            maxEval = max(maxEval, evaluation)
        return maxEval
    else:
        minEval = float('inf')
        for move in board.generate_legal_moves():
            evaluation = minimax(move, depth-1, True)
            minEval = min(minEval, evaluation)
        return minEval
```

# 5. AIとの対戦

最後に、実装したAIと実際に対戦してみましょう。ユーザーの入力を受け取り、AIが反応する仕組みを作ります。

```python
def play_shogi():
    board = ShogiBoard()
    while not game_over(board):
        user_move = input("Your move: ")
        board.apply_move(user_move)
        ai_move = minimax(board, 3, True)
        board.apply_move(ai_move)
        print(board)

play_shogi()
```

この基本的なガイドを参考に、自分だけの将棋AIを作成してみてください。プロセスを通じて、AI開発のスキルが向上するでしょう。

# 最後に

最後に、将棋AIの歴史とアルゴリズムについてまとめます。
ミニマックス法など、人間が評価関数を作成しなければならないAIは性能の向上の限界にぶつかったため、現在はAI同士が戦いながら強くなっていく教師なし学習で主に開発されています。

## 将棋AIの歴史

将棋AIの開発の歴史は、コンピュータ科学と人工知能の進化とともに進化してきました。以下にその主要な進展をまとめます。

### 1950年代～1970年代：黎明期
- **1950年代**: コンピュータチェスの開発が始まり、将棋のプログラムも模索されるようになる。 
- **1970年代**: 初期の将棋プログラムが開発される。これらは非常にシンプルで、基本的なルールに従った動きしかできなかった。

### 1980年代：基礎の確立
- **1982年**: 初の将棋専用コンピュータ「電王」が登場。 
- **1983年**: 初のコンピュータ将棋選手権が開催される。以降、毎年開催されるようになる。

### 1990年代：アルゴリズムの進化
- **1990年代初頭**: アルファベータ法などの探索アルゴリズムの導入により、コンピュータの強さが向上。
- **1997年**: 「Bonanza」などのプログラムが登場し、探索の効率化や評価関数の改良が進む。

### 2000年代：急速な発展
- **2005年**: Bonanzaが第15回世界コンピュータ将棋選手権で優勝。ボナンザメソッドと呼ばれる新しい手法が注目される。
- **2007年**: ボナンザメソッドの公開により、多くの将棋プログラムが強化される。

### 2010年代：ディープラーニングの導入
- **2012年**: コンピュータ将棋プログラム「Ponanza」が登場し、急速に強くなる。
- **2013年**: 将棋電王戦が始まり、トッププロ棋士とコンピュータの対決が注目される。
- **2015年**: Ponanzaが電王戦でプロ棋士に勝利。ディープラーニングの手法が導入される。

### 2020年代：AlphaZeroとその影響
- **2017年**: Google DeepMindのAlphaZeroが将棋、チェス、囲碁で圧倒的な強さを示す。自己学習型AIの可能性が広がる。
- **2020年代**: AlphaZeroの影響を受けたプログラムが多数開発され、コンピュータ将棋の研究がさらに進む。

### 現在と未来
現在では、将棋AIはプロ棋士にとっても重要なツールとなり、研究や対局の準備に欠かせないものとなっています。また、将棋AIの技術は他の分野への応用も期待されており、今後もその進化が続くと考えられています。

## 将棋AIのアルゴリズム
将棋AIのアルゴリズムは、探索アルゴリズムと評価関数の組み合わせにより実現されています。以下に主要なアルゴリズムについて詳しく説明します。

### 1. 探索アルゴリズム
将棋AIの探索アルゴリズムは、膨大な手の中から最善手を見つけるための技術です。以下は主要な探索アルゴリズムです。

#### ミニマックス法
ミニマックス法は、プレイヤー（自己）と相手が最善の手を指すと仮定して次の手を評価する方法です。自分の番では利益を最大化し、相手の番では利益を最小化することを目指します。

#### アルファベータ法
アルファベータ法は、ミニマックス法の改良版です。このアルゴリズムは、不必要な探索を省くために剪定（プルーニング）を行います。これにより、探索の効率が大幅に向上します。

#### モンテカルロ木探索（MCTS）
MCTSは、確率的な手法を用いて最善手を見つける方法です。シミュレーションを多数行い、その結果に基づいて手を選びます。特に終盤の複雑な局面で有効です。

### 2. 評価関数
評価関数は、盤面の状態を数値化してその価値を評価するものです。以下は評価関数の主要な要素です。

#### 材の評価
各駒の価値を数値化し、盤上の駒の総和で評価します。一般的に、駒の価値は以下のように設定されます。
- 歩：1
- 香車：3
- 桂馬：3
- 銀：5
- 金：6
- 角：8
- 飛車：9

#### 駒の位置評価
駒の位置や配置による価値も評価します。例えば、中央に駒を配置することが有利とされることが多いです。また、特定のパターン（囲いの形成など）も評価に影響します。

#### 静的評価と動的評価
- **静的評価**: 盤面の現在の状態を評価します。具体的には、駒の配置や持ち駒の数を基に評価します。
- **動的評価**: 将来の可能性を評価します。相手の手や自分の次の手を考慮して、より深い評価を行います。

### 3. 機械学習とディープラーニング
最近の将棋AIでは、機械学習やディープラーニングが重要な役割を果たしています。以下はその主要な技術です。

#### 教師あり学習
プロ棋士の対局データを用いて、AIに正しい手を学習させます。この方法により、AIはプロ棋士に匹敵する手を指せるようになります。

#### 強化学習
AIが自ら対局を行い、その結果に基づいて自己改善を行います。これにより、自己学習型のAIが誕生し、AlphaZeroのような強力な将棋AIが開発されました。

#### ディープニューラルネットワーク（DNN）
DNNは、深層学習を用いたネットワークで、複雑なパターンを学習し、高度な判断を行います。将棋AIでは、盤面の評価や次の手の選択にDNNが用いられています。

### まとめ
将棋AIのアルゴリズムは、探索アルゴリズムと評価関数の組み合わせにより実現されており、近年では機械学習やディープラーニングの技術が加わることで、さらなる進化を遂げています。これらの技術の発展により、将棋AIはプロ棋士に匹敵する、あるいはそれを超えるレベルにまで到達しています。